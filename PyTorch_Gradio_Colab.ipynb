{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13ZIMBBWgE2vq-YjU5OR7z7OMpf_w3jbX","authorship_tag":"ABX9TyM8Kk37sH3A/HFEOF1Vys1e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"WFImZyEAyTfh","executionInfo":{"status":"ok","timestamp":1716240422094,"user_tz":240,"elapsed":8482,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"outputs":[],"source":["# Import dependencies\n","import torch\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision.models import resnet18, ResNet18_Weights #pretrained model"]},{"cell_type":"code","source":["# Define the training and validation transforms for the data, add data aug to increase dateset sample\n","train_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),  # Flips images vertically\n","    transforms.RandomRotation(30),  # Increase rotation range. I've tried 10 and 20\n","    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),  # Increase color jitter\n","    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),  # Wider scale for random cropping\n","    transforms.RandomGrayscale(p=0.2),  # Randomly convert to grayscale\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"metadata":{"id":"uKTeRx25zo2k","executionInfo":{"status":"ok","timestamp":1716240422094,"user_tz":240,"elapsed":14,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n"],"metadata":{"id":"6luU4AvnzsJg","executionInfo":{"status":"ok","timestamp":1716240422094,"user_tz":240,"elapsed":13,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Load the entire dataset\n","data_dir = '/content/drive/MyDrive/AI Bootcamp/animals/animals'\n","full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n"],"metadata":{"id":"gMCSeNXBz4gg","executionInfo":{"status":"ok","timestamp":1716240422094,"user_tz":240,"elapsed":13,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define Animal Classes\n","animal_classes = ['cat', 'cow', 'coyote', 'deer', 'dog', 'donkey', 'fox', 'horse', 'owl', 'pig', 'possum', 'raccoon', 'sheep', 'wolf']\n","\n","# Define predator mapping (0: nonpredator, 1: predator, 2: both)\n","predator_mapping = {'cat': 2, 'cow': 0, 'coyote': 1, 'deer': 2, 'dog': 2, 'donkey': 0, 'fox': 1, 'horse': 0, 'owl': 1, 'pig': 0, 'possum': 1,\n","                    'raccoon': 1, 'sheep': 0, 'wolf': 1}\n","\n","predator_classes = ['nonpredator', 'predator', 'both']"],"metadata":{"id":"rezxHu5v2oTv","executionInfo":{"status":"ok","timestamp":1716240422094,"user_tz":240,"elapsed":13,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training, validation, and test sets\n","train_size = int(0.7 * len(full_dataset))\n","val_size = int(0.15 * len(full_dataset))\n","test_size = len(full_dataset) - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])"],"metadata":{"id":"kj84j5Iv3OYI","executionInfo":{"status":"ok","timestamp":1716240422306,"user_tz":240,"elapsed":224,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Apply validation transforms to val_dataset\n","val_dataset.dataset.transform = val_transforms"],"metadata":{"id":"GW5DS63F3boL","executionInfo":{"status":"ok","timestamp":1716240422307,"user_tz":240,"elapsed":225,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Create DataLoaders\n","batch_size = 64  # Adjust batch size. Tried 32 and 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2) # Changed num_workers from 4 to 2 based on Colab warning\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"],"metadata":{"id":"kS38HgQQ3edO","executionInfo":{"status":"ok","timestamp":1716240422308,"user_tz":240,"elapsed":5,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Create model\n","class AnimalClassifier(nn.Module):\n","    def __init__(self, num_animal_classes=14):\n","        super(AnimalClassifier, self).__init__()\n","        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # Pretrained model w/ weights\n","        self.model.fc = nn.Linear(self.model.fc.in_features, num_animal_classes)\n","\n","    def forward(self, x):\n","        return self.model(x)"],"metadata":{"id":"sy-7ah163vtA","executionInfo":{"status":"ok","timestamp":1716240422308,"user_tz":240,"elapsed":4,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","model = AnimalClassifier()"],"metadata":{"id":"Vo2llioX3zej","executionInfo":{"status":"ok","timestamp":1716240422934,"user_tz":240,"elapsed":630,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Use label smoothing\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)  # Use SGD with weight decay"],"metadata":{"id":"Fu6-33V234gB","executionInfo":{"status":"ok","timestamp":1716240422935,"user_tz":240,"elapsed":4,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Learning rate scheduler\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"metadata":{"id":"FZMVZUbL3-9H","executionInfo":{"status":"ok","timestamp":1716240422935,"user_tz":240,"elapsed":3,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Training function\n","def train(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return epoch_loss"],"metadata":{"id":"Y1E_cqPx4HVG","executionInfo":{"status":"ok","timestamp":1716240422935,"user_tz":240,"elapsed":3,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Validation function\n","def validate(model, val_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct_preds = 0\n","    total_preds = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * images.size(0)\n","\n","            _, preds = torch.max(outputs, 1)\n","            correct_preds += torch.sum(preds == labels.data)\n","            total_preds += len(labels)\n","\n","    epoch_loss = running_loss / len(val_loader.dataset)\n","    accuracy = correct_preds.double() / total_preds\n","    return epoch_loss, accuracy\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKmiEXBA4d6c","executionInfo":{"status":"ok","timestamp":1716240423116,"user_tz":240,"elapsed":184,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}},"outputId":"a15ddd0a-5924-414f-bea5-8e25d1012bbd"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AnimalClassifier(\n","  (model): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=14, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Received a os.fork() is incompatible with multithreaded code\n","# Chat GPT suggested the following fix\n","import multiprocessing as mp\n","\n","# Set the start method to 'spawn' at the beginning of your script\n","mp.set_start_method('spawn', force=True)\n","\n","\n","\n","# Train the model with early stopping\n","num_epochs = 50\n","patience = 5\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n","          f\"Train Loss: {train_loss:.4f}, \"\n","          f\"Val Loss: {val_loss:.4f}, \"\n","          f\"Val Accuracy: {val_accuracy:.4f}\")\n","\n","    scheduler.step()\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n","    else:\n","        epochs_no_improve += 1\n","\n","    if epochs_no_improve >= patience:\n","        print(f\"Early stopping triggered after {epoch+1} epochs\")\n","        break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kj1w_5jP4ir8","executionInfo":{"status":"ok","timestamp":1716243148528,"user_tz":240,"elapsed":2725414,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}},"outputId":"117d3d58-5926-46ab-a826-61944a183d2f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 2.3143, Val Loss: 1.2562, Val Accuracy: 0.7619\n","Epoch 2/50, Train Loss: 0.9390, Val Loss: 1.0513, Val Accuracy: 0.8333\n","Epoch 3/50, Train Loss: 0.7663, Val Loss: 1.1051, Val Accuracy: 0.8095\n","Epoch 4/50, Train Loss: 0.7047, Val Loss: 1.0530, Val Accuracy: 0.8333\n","Epoch 5/50, Train Loss: 0.6644, Val Loss: 1.0073, Val Accuracy: 0.8175\n","Epoch 6/50, Train Loss: 0.6496, Val Loss: 1.0440, Val Accuracy: 0.8175\n","Epoch 7/50, Train Loss: 0.6246, Val Loss: 0.9853, Val Accuracy: 0.8413\n","Epoch 8/50, Train Loss: 0.6087, Val Loss: 0.9698, Val Accuracy: 0.8333\n","Epoch 9/50, Train Loss: 0.6034, Val Loss: 0.9682, Val Accuracy: 0.8492\n","Epoch 10/50, Train Loss: 0.5991, Val Loss: 0.9695, Val Accuracy: 0.8492\n","Epoch 11/50, Train Loss: 0.5960, Val Loss: 0.9724, Val Accuracy: 0.8413\n","Epoch 12/50, Train Loss: 0.5930, Val Loss: 0.9700, Val Accuracy: 0.8413\n","Epoch 13/50, Train Loss: 0.5936, Val Loss: 0.9717, Val Accuracy: 0.8571\n","Epoch 14/50, Train Loss: 0.5921, Val Loss: 0.9706, Val Accuracy: 0.8492\n","Early stopping triggered after 14 epochs\n"]}]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/AI Bootcamp/animal_classifier_model.pt')"],"metadata":{"id":"ZEUEP4zQLEH3","executionInfo":{"status":"ok","timestamp":1716245589317,"user_tz":240,"elapsed":480,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Function to classify an image and return the animal and predator class\n","def classify_image(image):\n","    model.eval()\n","    with torch.no_grad():\n","        image = val_transforms(image).unsqueeze(0).to(device)\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs, 1)\n","        animal_class = animal_classes[predicted.item()]\n","        predator_class = predator_classes[predator_mapping[animal_class]]\n","        return animal_class, predator_class"],"metadata":{"id":"kgjlMa7_EHw8","executionInfo":{"status":"ok","timestamp":1716243188977,"user_tz":240,"elapsed":198,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!pip install gradio\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOwUKZ0SENhK","executionInfo":{"status":"ok","timestamp":1716243351806,"user_tz":240,"elapsed":24101,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}},"outputId":"f0f33e9a-b70b-40aa-8053-18302c588b63"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-4.31.4-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.16.4 (from gradio)\n","  Downloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Collecting typer<1.0,>=0.12 (from gradio)\n","  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n","  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n","Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=b4da502bb954edaac9fe30720593295b68f5c4c3f8c0f35199784f9205e9427f\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.9.4\n","    Uninstalling typer-0.9.4:\n","      Successfully uninstalled typer-0.9.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.31.4 gradio-client-0.16.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","from PIL import Image\n","\n","# Set up the Gradio interface\n","def predict(image):\n","    animal_class, predator_class = classify_image(image)\n","    return f\"Animal: {animal_class}, Category: {predator_class}\"\n","\n","interface = gr.Interface(fn=predict, inputs=gr.Image(type=\"pil\"), outputs=gr.Text(), title=\"Animal Classifier\")\n","interface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":625},"id":"jNgK4BcRE1MU","executionInfo":{"status":"ok","timestamp":1716243492349,"user_tz":240,"elapsed":2197,"user":{"displayName":"Sandy Griffin","userId":"01238413906686040842"}},"outputId":"ce7eac59-f3c5-4663-87bb-2f3340382116"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://ace4bff556d9a7f43c.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://ace4bff556d9a7f43c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":21}]}]}