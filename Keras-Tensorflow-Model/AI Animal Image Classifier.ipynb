{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b41cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import gradio as gr\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dd1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img):\n",
    "    class_names = ['bison', 'boar', 'cat', 'chicken', 'cow', 'coyote', 'deer', 'dog', 'donkey', 'duck', 'fox', 'goat', 'goose', \n",
    "               'hare', 'hedgehog', 'horse', 'mouse', 'owl', 'ox', 'pig', 'possum', 'raccoon', 'rat', 'sheep', 'snake', 'squirrel', \n",
    "               'turkey', 'wolf']\n",
    "    model = keras.models.load_model('animal_classifier_model.keras')\n",
    "    im = ImageOps.pad(img, (224, 224), color=\"black\")\n",
    "    image = np.asarray(im)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    prediction = model.predict(image)\n",
    "    prediction = prediction.reshape(28).tolist()\n",
    "    highest_prob = round(max(prediction) * 100,1)\n",
    "    pred_class = class_names[np.argmax(prediction, axis = -1)]\n",
    "    value = f\"The predicted animal is a {pred_class} with a probability of {highest_prob}%.\"\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc67ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x317aa60e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3323ebd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/blocks.py\", line 1843, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/blocks.py\", line 1578, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/components/image.py\", line 171, in preprocess\n",
      "    im = PIL.Image.open(file_path)\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/PIL/Image.py\", line 3283, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/private/var/folders/3c/9ft0ypz97s95314t_ng03_br0000gn/T/gradio/7935c44b349be9d1bc9b04a13b7bfb435dcd1b4d/goose.avif'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/blocks.py\", line 1843, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/blocks.py\", line 1578, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/gradio/components/image.py\", line 171, in preprocess\n",
      "    im = PIL.Image.open(file_path)\n",
      "  File \"/Users/schneggz/anaconda3/envs/dev/lib/python3.10/site-packages/PIL/Image.py\", line 3283, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/private/var/folders/3c/9ft0ypz97s95314t_ng03_br0000gn/T/gradio/9eac32c8f451e830b49ef490237ac4935fc1e773/snake.avif'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the Gradio Interface application function to take in an image and predict what animal is shown\n",
    "app = gr.Interface(fn=prediction, inputs=gr.Image(type=\"pil\"), outputs=gr.Textbox())\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b01e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
